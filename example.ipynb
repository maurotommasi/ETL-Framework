{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ETL Pipeline ProcessID: 16144\n",
      "Linking Pipeline flows for ETL Pipeline\n",
      "Creating Thread...\n",
      "Creating Thread...\n",
      "Wait for first execution at 2023-11-04 16:34:00 for IN1\n",
      "Wait for first execution at 2023-11-04 16:34:00 for IN2\n",
      "Running Ingestion IN1...\n",
      "Running Ingestion IN2...\n",
      "Ingestion IN1 successfully completed!\n",
      "Running Transformation TR1 for Ingestion IN1...\n",
      "Trasformation TR1 for ingestion IN1 Done!\n",
      "Loading data from Ingestion IN1...\n",
      "Ingestion IN2 successfully completed!\n",
      "Loading data from Ingestion IN2...\n",
      "Loaded data from Ingestion IN1!\n",
      "Loaded data from Ingestion IN2!\n",
      "Next execution for IN1 will be at 2023-11-04 16:34:30\n",
      "Next execution for IN2 will be at 2023-11-04 16:35:00\n",
      "Running Ingestion IN1...\n",
      "Ingestion IN1 successfully completed!\n",
      "Running Transformation TR1 for Ingestion IN1...\n",
      "Trasformation TR1 for ingestion IN1 Done!\n",
      "Loading data from Ingestion IN1...\n",
      "Loaded data from Ingestion IN1!\n",
      "Next execution for IN1 will be at 2023-11-04 16:35:00\n"
     ]
    }
   ],
   "source": [
    "from ETL.Pipeline import Pipeline, FlowConfig\n",
    "from ETL.modules.DataSource import DataSourceConfig\n",
    "from ETL.modules.Encoder import EncoderConfig\n",
    "from ETL.modules.Loader import LoaderConfig\n",
    "from ETL.modules.Utils import Utils\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "import os\n",
    "# Datasource Config\n",
    "\n",
    "ds_config = DataSourceConfig().custom_source_config()\n",
    "\n",
    "# Ingestion Function\n",
    "\n",
    "def query_wp_post(feedback):\n",
    "    df = pd.DataFrame()\n",
    "    latest_date = \"\"\n",
    "    if \"latest_date\" in feedback:\n",
    "        latest_date = feedback['latest_date']\n",
    "    try:\n",
    "        host = \"127.0.0.1\"\n",
    "        user = \"root\"\n",
    "        password = \"\"\n",
    "        database = \"mt-engineering\"\n",
    "        connection = mysql.connector.connect(host=host, user=user, password=password, database=database)\n",
    "        if connection.is_connected():\n",
    "            query = f\"Select post_title, post_status, post_date from wp_posts\"# where post_date > '{latest_date}'\"\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute(query)\n",
    "            column_names = [description[0] for description in cursor.description]\n",
    "            results = cursor.fetchall()\n",
    "            if len(results) > 0:\n",
    "                df = pd.DataFrame(results, columns=column_names)\n",
    "                df[\"date_time_execution\"] = datetime.now()\n",
    "                feedback['latest_date'] = max(df['post_date'])\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "        else:\n",
    "            print(f\"Not Connected to host: {host} - database: {database}\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Error: \", err)\n",
    "    return df, feedback\n",
    "\n",
    "def query_wp_postmeta(feedback):\n",
    "    df = pd.DataFrame()\n",
    "    try:\n",
    "        host = \"127.0.0.1\"\n",
    "        user = \"root\"\n",
    "        password = \"\"\n",
    "        database = \"mt-engineering\"\n",
    "        connection = mysql.connector.connect(host=host, user=user, password=password, database=database)\n",
    "        if connection.is_connected():\n",
    "            query = f\"Select meta_id from wp_postmeta\"\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute(query)\n",
    "            column_names = [description[0] for description in cursor.description]\n",
    "            results = cursor.fetchall()\n",
    "            if len(results) > 0:\n",
    "                df = pd.DataFrame(results, columns=column_names)\n",
    "                df[\"date_time_execution\"] = datetime.now()\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "        else:\n",
    "            print(f\"Not Connected to host: {host} - database: {database}\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Error: \", err)\n",
    "    return df, feedback\n",
    "\n",
    "# Encoder Config\n",
    "\n",
    "cols_source = ['post_title', 'post_status']\n",
    "cols_dest = ['meta_id', 'POST_STATUS_UPPER']\n",
    "en_config = EncoderConfig().custom_encoder_config(cols_source, cols_dest)\n",
    "\n",
    "cols_source = ['meta_id']\n",
    "cols_dest = ['META_ID']\n",
    "en_config2 = EncoderConfig().custom_encoder_config(cols_source, cols_dest)\n",
    "\n",
    "# Transformation Function\n",
    "\n",
    "def upper_meta_value(df):\n",
    "    df['post_status'] = df['post_status'].str.upper()\n",
    "    return df\n",
    "\n",
    "# Loader Config / Function\n",
    "\n",
    "ld_config = LoaderConfig().custom_loader()\n",
    "\n",
    "def append_to_file_csv_1(df):\n",
    "    path = \"./export/excel_export_test.csv\"\n",
    "    if os.path.exists(path):\n",
    "        result = pd.concat([pd.read_csv(path), df])\n",
    "        result.to_csv(path, index=True)\n",
    "    else:\n",
    "        df.to_csv(path, index=True)\n",
    "\n",
    "def append_to_file_csv_2(df):\n",
    "    path = \"./export/excel_export_test_2.csv\"\n",
    "    if os.path.exists(path):\n",
    "        result = pd.concat([pd.read_csv(path), df])\n",
    "        result.to_csv(path, index=True)\n",
    "    else:\n",
    "        df.to_csv(path, index=True)\n",
    "\n",
    "# Control Config - Create Started date/time\n",
    "\n",
    "date_string = \"2023-11-01 00:00:00\"\n",
    "date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "start_datetime = datetime.strptime(date_string, date_format)\n",
    "\n",
    "# Pipeline Object Creation\n",
    "\n",
    "pipeline = Pipeline(\"ETL Pipeline\")\n",
    "\n",
    "# Create Pipeline Elements\n",
    "\n",
    "## Flow 1 Instances\n",
    "\n",
    "pipeline.create_datasource('DS1', ds_config)\n",
    "pipeline.create_encoder('EN1', en_config)\n",
    "pipeline.create_ingestion('IN1', query_wp_post)\n",
    "pipeline.create_control('CT1', 30, 3600, start_datetime)\n",
    "pipeline.create_process('TR1', [upper_meta_value])\n",
    "pipeline.create_loader('LD1', ld_config, append_to_file_csv_1)\n",
    "\n",
    "## Flow 2 New Istances\n",
    "\n",
    "pipeline.create_ingestion('IN2', query_wp_postmeta)\n",
    "pipeline.create_encoder('EN2', en_config2)\n",
    "pipeline.create_control('CT2', 60, 3600, start_datetime)\n",
    "pipeline.create_loader('LD2', ld_config, append_to_file_csv_2)\n",
    "\n",
    "# Flow Config\n",
    "\n",
    "flow_config = FlowConfig()\n",
    "\n",
    "flow1 = flow_config.create_flow(\n",
    "    ID_datasource='DS1',\n",
    "    ID_encoder='EN1',\n",
    "    ID_ingestion='IN1',\n",
    "    ID_control='CT1',\n",
    "    ID_process='TR1',\n",
    "    ID_loader='LD1')\n",
    "\n",
    "flow2 = flow_config.create_flow(\n",
    "    ID_datasource='DS1',\n",
    "    ID_encoder='EN2',\n",
    "    ID_ingestion='IN2',\n",
    "    ID_control='CT2',\n",
    "    ID_loader='LD2')\n",
    "\n",
    "flow_config.add_flow(flow1)\n",
    "flow_config.add_flow(flow2)\n",
    "\n",
    "# Set Pipeline flow\n",
    "\n",
    "pipeline.set_flow(flow_config.get_flow_config())\n",
    "\n",
    "# Pipeline Start \n",
    "\n",
    "pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
